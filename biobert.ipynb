{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidsolow/.pyenv/versions/3.11.1/envs/med-abbrev-mystery/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-12 18:55:04.893153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-12 18:55:04.906874: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-12 18:55:04.906899: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-12 18:55:04.917335: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-12 18:55:05.637883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 18:55:06.244941: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-12 18:55:06.248901: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-12 18:55:06.251889: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>label</th>\n",
       "      <th>abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14145090</td>\n",
       "      <td>velvet antlers vas are commonly used in tradit...</td>\n",
       "      <td>63</td>\n",
       "      <td>transverse aortic constriction</td>\n",
       "      <td>TAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1900667</td>\n",
       "      <td>the clinical features of our cases demonstrate...</td>\n",
       "      <td>85</td>\n",
       "      <td>hodgkins lymphoma</td>\n",
       "      <td>HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8625554</td>\n",
       "      <td>ceftobiprole bpr is an investigational cephalo...</td>\n",
       "      <td>90</td>\n",
       "      <td>methicillinsusceptible s aureus</td>\n",
       "      <td>MSSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8157202</td>\n",
       "      <td>we have taken a basic biologic RPA to elucidat...</td>\n",
       "      <td>26</td>\n",
       "      <td>parathyroid hormonerelated protein</td>\n",
       "      <td>PTHrP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4846741</td>\n",
       "      <td>gb virus c gbvc or HGV hgv is transmitted by t...</td>\n",
       "      <td>5</td>\n",
       "      <td>hepatitis g virus</td>\n",
       "      <td>HGV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  abstract_id                                               text  \\\n",
       "0           0     14145090  velvet antlers vas are commonly used in tradit...   \n",
       "1           1      1900667  the clinical features of our cases demonstrate...   \n",
       "2           2      8625554  ceftobiprole bpr is an investigational cephalo...   \n",
       "3           3      8157202  we have taken a basic biologic RPA to elucidat...   \n",
       "5           5      4846741  gb virus c gbvc or HGV hgv is transmitted by t...   \n",
       "\n",
       "   location                               label abbreviation  \n",
       "0        63      transverse aortic constriction          TAC  \n",
       "1        85                   hodgkins lymphoma           HD  \n",
       "2        90     methicillinsusceptible s aureus         MSSA  \n",
       "3        26  parathyroid hormonerelated protein        PTHrP  \n",
       "5         5                   hepatitis g virus          HGV  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=200\n",
    "\n",
    "def process_location(location):\n",
    "    return list(map(int, eval(location)))[0]\n",
    "\n",
    "def process_label(label):\n",
    "    return eval(label)[0]\n",
    "\n",
    "# Reading and processing training data\n",
    "train_df = pd.read_csv('data/medal_train.csv')\n",
    "train_df['location'] = train_df['location'].map(process_location)\n",
    "train_df['label'] = train_df['label'].map(process_label)\n",
    "train_df['abbreviation'] = train_df.apply(lambda row: row['text'].split()[row['location']], axis=1)\n",
    "train_df = train_df[train_df['location'] <= max_len-51]\n",
    "\n",
    "# Reading and processing validation data\n",
    "val_df = pd.read_csv('data/medal_val.csv')\n",
    "val_df['location'] = val_df['location'].map(process_location)\n",
    "val_df['label'] = val_df['label'].map(process_label)\n",
    "val_df['abbreviation'] = val_df.apply(lambda row: row['text'].split()[row['location']], axis=1)\n",
    "val_df = val_df[val_df['location'] <= max_len-51]\n",
    "\n",
    "# Reading and processing test data\n",
    "test_df = pd.read_csv('data/medal_test.csv')\n",
    "test_df['location'] = test_df['location'].map(process_location)\n",
    "test_df['label'] = test_df['label'].map(process_label)\n",
    "test_df['abbreviation'] = test_df.apply(lambda row: row['text'].split()[row['location']], axis=1)\n",
    "test_df = test_df[test_df['location'] <= max_len-51]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['velvet antlers vas are commonly used in traditional chinese medicine and invigorant and contain many PET components for health promotion the velvet antler peptide svap is one of active components in vas based on structural study the svap interacts with tgfÎ² receptors and disrupts the tgfÎ² pathway we hypothesized that svap prevents cardiac fibrosis from pressure overload by blocking tgfÎ² signaling SDRs underwent TAC tac or a sham operation T3 one month rats received either svap mgkgday or vehicle for an additional one month tac surgery induced significant cardiac dysfunction FB activation and fibrosis these effects were improved by treatment with svap in the heart tissue tac remarkably increased the expression of tgfÎ² and connective tissue growth factor ctgf ROS species C2 and the phosphorylation C2 of smad and ERK kinases erk svap inhibited the increases in reactive oxygen species C2 ctgf expression and the phosphorylation of smad and erk but not tgfÎ² expression in cultured cardiac fibroblasts angiotensin ii ang ii had similar effects compared to tac surgery such as increases in Î±smapositive CFs and collagen synthesis svap eliminated these effects by disrupting tgfÎ² IB to its receptors and blocking ang iitgfÎ² downstream signaling these results demonstrated that svap has antifibrotic effects by blocking the tgfÎ² pathway in CFs',\n",
       "       'the clinical features of our cases demonstrated some of the already known characteristics of the variable spectrum of hiv infection da are the most important risk category in italy of the arc cases evolved into aids during a month followup on average the most frequent oi in our aids cases were pcp c albicans esophagitis and chronic mucocutaneous ulcers an high percentage of neurologic involvement from hiv was observed and HM were encountered in aids ks and undifferentiated b lymphoma as well as in arc HD statistically significant worsening of the immunologic situation is evident as the disease progresses from las to aids G1 b lymphocytes represent most of the cells of the germinal center during the hyperplastic stage of lymphadenopathy reversal of the tt ratio appears early during the initial stage of lymphadenopathy and is due to a decrease of cd and a relative increase of cd also destruction of the follicular dendritic cells is an early feature which becomes more evident as the disease advances and the lymph node evolves toward progressive involution activated blymphocyte augmentation with polyclonal ig secretion appears to be related to TI b stimulation by coinfection such as cmv ebv and hbv the increase of CD8 lymphocytes seems to be partly related to the excessive activation of b lymphocytes and partially directed to the cells INF by hiv or coated with its proteins the destruction of follicular dendritic cells has been interpreted not only as a killer effect of the virus but also as a result of the intervention of ctl sensitized to the cells containing the virus their destruction may contribute to the impaired recognition of soluble antigen which is one of the main features of the immune deficiency of hiv infection'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = train_df['text'].values[:10000]\n",
    "train_abbrv = train_df['abbreviation'].values[:10000]\n",
    "train_loc = train_df['location'].values[:10000]\n",
    "train_label = train_df['label'].values[:10000]\n",
    "\n",
    "val_text = val_df['text'].values[:1000]\n",
    "val_abbrv = val_df['abbreviation'].values[:100]\n",
    "val_loc = val_df['location'].values[:1000]\n",
    "val_label = val_df['label'].values[:1000]\n",
    "\n",
    "test_text = test_df['text'].values[:100]\n",
    "test_abbrv = test_df['abbreviation'].values[:1000]\n",
    "test_loc = test_df['location'].values[:1000]\n",
    "test_label = test_df['label'].values[:1000]\n",
    "\n",
    "del train_df\n",
    "del val_df\n",
    "del test_df\n",
    "gc.collect()\n",
    "\n",
    "train_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acronyms = train_abbrv.tolist() + val_abbrv.tolist() + test_abbrv.tolist()\n",
    "# expansions = train_label.tolist() + val_label.tolist() + test_label.tolist()\n",
    "# expansions = [word for expansion in expansions for word in expansion.split()]\n",
    "# new_terms = list(set(acronyms + expansions))\n",
    "\n",
    "model_checkpoint = \"Charangan/MedBERT\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_checkpoint)\n",
    "# num_new_tokens = tokenizer.add_tokens(new_terms)\n",
    "# print(f\"Number of new tokens added: {num_new_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts, locations, expansions, tokenizer=tokenizer, max_len=max_len):\n",
    "    input_ids = []\n",
    "    token_type_ids = []\n",
    "    attention_masks = []\n",
    "    extended_texts = []\n",
    "    encoded_labels = []\n",
    "\n",
    "    for text, loc, expansion in zip(texts, locations, expansions):\n",
    "        encoded_input = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        \n",
    "        input_ids.append(encoded_input['input_ids'])\n",
    "        token_type_ids.append(encoded_input['token_type_ids'])\n",
    "        attention_masks.append(encoded_input['attention_mask'])\n",
    "\n",
    "        # Labels\n",
    "        label = text.split()\n",
    "        label = label[:loc] + expansion.split() + label[loc+1:]\n",
    "        label = ' '.join(label)\n",
    "        extended_texts.append(label)\n",
    "        encoded_output = tokenizer.encode_plus(\n",
    "            label,\n",
    "            add_special_tokens=False,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        encoded_labels.append(encoded_output['input_ids'])\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=np.int32).squeeze()\n",
    "    token_type_ids = np.array(token_type_ids, dtype=np.int32).squeeze()\n",
    "    attention_masks = np.array(attention_masks, dtype=np.int32).squeeze()\n",
    "    encoded_labels = np.array(encoded_labels, dtype=np.int32).squeeze()\n",
    "\n",
    "    print(\"First text:\\n\", texts[0])\n",
    "    print(\"First location:\", locations[0])\n",
    "    print(\"First acronym:\", texts[0].split()[locations[0]])\n",
    "    print(\"First expansion:\", expansions[0])\n",
    "    print(\"First text with expansion:\\n\", extended_texts[0])\n",
    "    decoded_tokens = tokenizer.convert_ids_to_tokens(encoded_labels[0])\n",
    "    print(\"First label with expansion:\\n\", tokenizer.convert_tokens_to_string(decoded_tokens))\n",
    "\n",
    "    return input_ids, token_type_ids, attention_masks, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 18:57:29.585023: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-12 18:57:29.591836: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-12 18:57:29.596731: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-12 18:57:29.754502: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-12 18:57:29.756219: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-12 18:57:29.757720: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-12 18:57:29.759186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9753 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First text:\n",
      " velvet antlers vas are commonly used in traditional chinese medicine and invigorant and contain many PET components for health promotion the velvet antler peptide svap is one of active components in vas based on structural study the svap interacts with tgfÎ² receptors and disrupts the tgfÎ² pathway we hypothesized that svap prevents cardiac fibrosis from pressure overload by blocking tgfÎ² signaling SDRs underwent TAC tac or a sham operation T3 one month rats received either svap mgkgday or vehicle for an additional one month tac surgery induced significant cardiac dysfunction FB activation and fibrosis these effects were improved by treatment with svap in the heart tissue tac remarkably increased the expression of tgfÎ² and connective tissue growth factor ctgf ROS species C2 and the phosphorylation C2 of smad and ERK kinases erk svap inhibited the increases in reactive oxygen species C2 ctgf expression and the phosphorylation of smad and erk but not tgfÎ² expression in cultured cardiac fibroblasts angiotensin ii ang ii had similar effects compared to tac surgery such as increases in Î±smapositive CFs and collagen synthesis svap eliminated these effects by disrupting tgfÎ² IB to its receptors and blocking ang iitgfÎ² downstream signaling these results demonstrated that svap has antifibrotic effects by blocking the tgfÎ² pathway in CFs\n",
      "First location: 63\n",
      "First acronym: TAC\n",
      "First expansion: transverse aortic constriction\n",
      "First text with expansion:\n",
      " velvet antlers vas are commonly used in traditional chinese medicine and invigorant and contain many PET components for health promotion the velvet antler peptide svap is one of active components in vas based on structural study the svap interacts with tgfÎ² receptors and disrupts the tgfÎ² pathway we hypothesized that svap prevents cardiac fibrosis from pressure overload by blocking tgfÎ² signaling SDRs underwent transverse aortic constriction tac or a sham operation T3 one month rats received either svap mgkgday or vehicle for an additional one month tac surgery induced significant cardiac dysfunction FB activation and fibrosis these effects were improved by treatment with svap in the heart tissue tac remarkably increased the expression of tgfÎ² and connective tissue growth factor ctgf ROS species C2 and the phosphorylation C2 of smad and ERK kinases erk svap inhibited the increases in reactive oxygen species C2 ctgf expression and the phosphorylation of smad and erk but not tgfÎ² expression in cultured cardiac fibroblasts angiotensin ii ang ii had similar effects compared to tac surgery such as increases in Î±smapositive CFs and collagen synthesis svap eliminated these effects by disrupting tgfÎ² IB to its receptors and blocking ang iitgfÎ² downstream signaling these results demonstrated that svap has antifibrotic effects by blocking the tgfÎ² pathway in CFs\n",
      "First label with expansion:\n",
      " velvet antlers vas are commonly used in traditional chinese medicine and invigorant and contain many PET components for health promotion the velvet antler peptide svap is one of active components in vas based on structural study the svap interacts with tgfÎ² receptors and disrupts the tgfÎ² pathway we hypothesized that svap prevents cardiac fibrosis from pressure overload by blocking tgfÎ² signaling SDRs underwent transverse aortic constriction tac or a sham operation T3 one month rats received either svap mgkgday or vehicle for an additional one month tac surgery induced significant cardiac dysfunction FB activation and fibrosis these effects were improved by treatment with svap in the heart tissue tac remarkably increased the expression of tgfÎ² and connective tissue growth factor ctgf ROS species C2 and the phosph\n",
      "Val------------------------------\n",
      "First text:\n",
      " different electrocardiographic changes have been described during thrombolytic therapy for AIM to indicate successful reperfusion the occluded coronary artery also can be reopened by percutaneous TCA ptca this study was performed to compare electrocardiographic changes during primary or rescue ptca and thrombolytic therapy the electrocardiographic changes were studied directly at the moment of reperfusion during ptca\n",
      "First location: 25\n",
      "First acronym: TCA\n",
      "First expansion: transluminal coronary angioplasty\n",
      "First text with expansion:\n",
      " different electrocardiographic changes have been described during thrombolytic therapy for AIM to indicate successful reperfusion the occluded coronary artery also can be reopened by percutaneous transluminal coronary angioplasty ptca this study was performed to compare electrocardiographic changes during primary or rescue ptca and thrombolytic therapy the electrocardiographic changes were studied directly at the moment of reperfusion during ptca\n",
      "First label with expansion:\n",
      " different electrocardiographic changes have been described during thrombolytic therapy for AIM to indicate successful reperfusion the occluded coronary artery also can be reopened by percutaneous transluminal coronary angioplasty ptca this study was performed to compare electrocardiographic changes during primary or rescue ptca and thrombolytic therapy the electrocardiographic changes were studied directly at the moment of reperfusion during ptca [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Test-----------------------------\n",
      "First text:\n",
      " we developed an animal model of chronic allergic airway disease by repeatedly exposing nine sheep to tracheal instillation of ascaris antigen until stable increase in RL at three times control in six reactive sheep group c was obtained they were then compared to the three nonreactive sheep group b and a control group of eight sheep exposed to saline only group a in terms of pulmonary CF tests and bronchoalveolar lavage bal analyses RL was cm holsec in group a in group b and in group c trapping volume FRC by plethysmography and by helium rebreathing technique was l in group a in group b and in group c UP resistance at PF did not differ between any two CG but UP resistance near residual volume was cm holsec in a in b and in c in bal total cells were x ml in a in b and in c macrophages in bal were in a in b and in c neutrophils were in a in b in c eosinophils were in a in b and in c p less than group c versus group a total proteins albumin ALP phosphatase and fibronectin did not differ between groupsabstract truncated at words\n",
      "First location: 89\n",
      "First acronym: FRC\n",
      "First expansion: functional residual capacity\n",
      "First text with expansion:\n",
      " we developed an animal model of chronic allergic airway disease by repeatedly exposing nine sheep to tracheal instillation of ascaris antigen until stable increase in RL at three times control in six reactive sheep group c was obtained they were then compared to the three nonreactive sheep group b and a control group of eight sheep exposed to saline only group a in terms of pulmonary CF tests and bronchoalveolar lavage bal analyses RL was cm holsec in group a in group b and in group c trapping volume functional residual capacity by plethysmography and by helium rebreathing technique was l in group a in group b and in group c UP resistance at PF did not differ between any two CG but UP resistance near residual volume was cm holsec in a in b and in c in bal total cells were x ml in a in b and in c macrophages in bal were in a in b and in c neutrophils were in a in b in c eosinophils were in a in b and in c p less than group c versus group a total proteins albumin ALP phosphatase and fibronectin did not differ between groupsabstract truncated at words\n",
      "First label with expansion:\n",
      " we developed an animal model of chronic allergic airway disease by repeatedly exposing nine sheep to tracheal instillation of ascaris antigen until stable increase in RL at three times control in six reactive sheep group c was obtained they were then compared to the three nonreactive sheep group b and a control group of eight sheep exposed to saline only group a in terms of pulmonary CF tests and bronchoalveolar lavage bal analyses RL was cm holsec in group a in group b and in group c trapping volume functional residual capacity by plethysmography and by helium rebreathing technique was l in group a in group b and in group c UP resistance at PF did not differ between any two CG but UP resistance near residual volume was cm holsec in a in b and in c in bal total cells were x ml in a in b and in c macrophages in bal were in a\n"
     ]
    }
   ],
   "source": [
    "print(\"Train----------------------------\")\n",
    "train_data = tokenize(train_text,\n",
    "                      train_loc,\n",
    "                      train_label)\n",
    "train_input_ids = train_data[0]\n",
    "train_token_type_ids = train_data[1]\n",
    "train_attention_masks = train_data[2]\n",
    "train_encoded_labels = train_data[3]\n",
    "\n",
    "print(\"Val------------------------------\")\n",
    "val_data = tokenize(val_text,\n",
    "                    val_loc,\n",
    "                    val_label)\n",
    "val_input_ids = val_data[0]\n",
    "val_token_type_ids = val_data[1]\n",
    "val_attention_masks = val_data[2]\n",
    "val_encoded_labels = val_data[3]\n",
    "\n",
    "print(\"Test-----------------------------\")\n",
    "test_data = tokenize(test_text,\n",
    "                     test_loc,\n",
    "                     test_label)\n",
    "test_input_ids = test_data[0]\n",
    "test_token_type_ids = test_data[1]\n",
    "test_attention_masks = test_data[2]\n",
    "test_encoded_labels = test_data[3]\n",
    "\n",
    "del train_text\n",
    "del train_loc\n",
    "del train_label\n",
    "del val_text\n",
    "del val_loc\n",
    "del val_label\n",
    "del test_text\n",
    "del test_loc\n",
    "del test_label\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " attention_mask (InputLayer  [(None, 200)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_ids (InputLayer)      [(None, 200)]                0         []                            \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer  [(None, 200)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel  TFBaseModelOutputWithPooli   1083102   ['attention_mask[0][0]',      \n",
      " )                           ngAndCrossAttentions(last_   72         'input_ids[0][0]',           \n",
      "                             hidden_state=(None, 200, 7              'token_type_ids[0][0]']      \n",
      "                             68),                                                                 \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 200, 28996)           2229792   ['tf_bert_model[0][0]']       \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 130608196 (498.23 MB)\n",
      "Trainable params: 130608196 (498.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "token_type_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"token_type_ids\")\n",
    "attention_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "bert_inputs = {'input_ids': input_ids,\n",
    "               'token_type_ids': token_type_ids,\n",
    "               'attention_mask': attention_mask}\n",
    "\n",
    "medbert_model = TFBertModel.from_pretrained(model_checkpoint, from_pt=True)\n",
    "#medbert_model.resize_token_embeddings(len(tokenizer))\n",
    "medbert_model.trainable = True\n",
    "\n",
    "bert_outputs = medbert_model(bert_inputs)\n",
    "last_hidden_state = bert_outputs.last_hidden_state\n",
    "\n",
    "num_labels = tokenizer.vocab_size\n",
    "output = tf.keras.layers.Dense(num_labels, activation='softmax', name='output')(last_hidden_state)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids,\n",
    "                               token_type_ids,\n",
    "                               attention_mask],\n",
    "                               outputs=output)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720825122.086258   62228 service.cc:145] XLA service 0x78b0f161a590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1720825122.086281   62228 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-07-12 18:58:42.093993: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-12 18:58:42.116170: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902\n",
      "I0000 00:00:1720825122.163675   62228 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 177s 230ms/step - loss: 6.3552 - accuracy: 0.2358 - val_loss: 5.2990 - val_accuracy: 0.3168\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 135s 216ms/step - loss: 4.7814 - accuracy: 0.3662 - val_loss: 4.3331 - val_accuracy: 0.4027\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 131s 210ms/step - loss: 3.9146 - accuracy: 0.4548 - val_loss: 3.7662 - val_accuracy: 0.4699\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 123s 198ms/step - loss: 3.2302 - accuracy: 0.5299 - val_loss: 3.4768 - val_accuracy: 0.4885\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 134s 214ms/step - loss: 2.7181 - accuracy: 0.5826 - val_loss: 3.3295 - val_accuracy: 0.5066\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [train_input_ids, train_token_type_ids, train_attention_masks],\n",
    "    train_encoded_labels,\n",
    "    validation_data=([val_input_ids, val_token_type_ids, val_attention_masks,],\n",
    "                      val_encoded_labels, ),\n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 113ms/step - loss: 3.2621 - accuracy: 0.5181\n",
      "Test Loss: 3.2620556354522705\n",
      "Test Accuracy: 0.5181000232696533\n",
      "4/4 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 19:24:39.029432: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2319680000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First X Test:\n",
      " [CLS] we developed an animal model of chronic allergic airway disease by repeatedly exposing nine sheep to tracheal instillation of ascaris antigen until stable increase in RL at three times control in six reactive sheep group c was obtained they were then compared to the three nonreactive sheep group b and a control group of eight sheep exposed to saline only group a in terms of pulmonary CF tests and bronchoalveolar lavage bal analyses RL was cm holsec in group a in group b and in group c trapping volume FRC by plethysmography and by helium rebreathing technique was l in group a in group b and in group c UP resistance at PF did not differ between any two CG but UP resistance near residual volume was cm holsec in a in b and in c in bal total cells were x ml in a in b and in c macrophages in bal were in [SEP]\n",
      "First Y True:\n",
      " we developed an animal model of chronic allergic airway disease by repeatedly exposing nine sheep to tracheal instillation of ascaris antigen until stable increase in RL at three times control in six reactive sheep group c was obtained they were then compared to the three nonreactive sheep group b and a control group of eight sheep exposed to saline only group a in terms of pulmonary CF tests and bronchoalveolar lavage bal analyses RL was cm holsec in group a in group b and in group c trapping volume functional residual capacity by plethysmography and by helium rebreathing technique was l in group a in group b and in group c UP resistance at PF did not differ between any two CG but UP resistance near residual volume was cm holsec in a in b and in c in bal total cells were x ml in a in b and in c macrophages in bal were in a\n",
      "First Y Pred:\n",
      " the developed an animal model of chronic allergic airway disease by injected neon nine sheep to tracheal instillation of ascaris antigen until rapid increase in RL at three times control in six selective sheep group c was obtained they were then compared to the three nonreactive bacteria group b and a control group of eight sheep exposed to saline only group a in terms of pulmonary CF tests and bronchoalveolar lavage bal analysis RL was cm holsec in group a in group b and in group ccell volume FR by plethyscography and by hela rebraathed procedure was was in group group in group b b in group in in resistance at p PF not not not between no two two twoG C but SE volume volume volume was min ha micro in a in b b b b b b in in were were m m m m in m b b b in inhilsss in in in in the\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(\n",
    "    [test_input_ids, test_token_type_ids, test_attention_masks],\n",
    "    test_encoded_labels\n",
    ")\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "predictions = model.predict([test_input_ids, test_token_type_ids, test_attention_masks])\n",
    "y_pred = np.argmax(predictions, axis=-1)\n",
    "y_true = test_encoded_labels\n",
    "\n",
    "print(\"First X Test:\\n\", tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(test_input_ids[0])))\n",
    "print(\"First Y True:\\n\", tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(y_true[0])))\n",
    "print(\"First Y Pred:\\n\", tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(y_pred[0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med-abbrev-mystery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
