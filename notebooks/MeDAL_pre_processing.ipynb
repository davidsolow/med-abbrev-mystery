{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuiuO9wAqkfakPCgtiMhVY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidsolow/med-abbrev-mystery/blob/kiara/MeDAL_pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing of MeDAL Dataset for use in fine-tuning BERT models\n",
        "### Steps:\n",
        "1. Import data from Drive, read CSVs, convert to Pandas dataframes\n",
        "2. Clean location and label columns\n",
        "3. Select rows with location < max_location and add abbreviation column\n",
        "4. Convert labels to integers and make label dictionary\n",
        "5. Mask abbreviations with '[MASK]'\n"
      ],
      "metadata": {
        "id": "0N6jJy5pd1BD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HsUZ3PNdqwr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"drive/MyDrive/266Project/train-3.csv\")\n",
        "test = pd.read_csv(\"drive/MyDrive/266Project/test.csv\")\n",
        "validation = pd.read_csv(\"drive/MyDrive/266Project/validation.csv\")"
      ],
      "metadata": {
        "id": "t5wvp1OKeRkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning location and label columns\n",
        "def clean_location(location):\n",
        "  \"\"\"Takes a number in brackets as input and reterns the number as an int\"\"\"\n",
        "  return int(str(location).strip(\"[]\"))\n",
        "\n",
        "def clean_label(label):\n",
        "  \"\"\"Takes a label in brackets and quotes as input and reterns the label as a string\"\"\"\n",
        "  return label.strip(\"[]'\")\n",
        "\n",
        "for dataset in [train, test, validation]:\n",
        "  dataset['location'] = dataset['location'].apply(clean_location)\n",
        "  dataset['label'] = dataset['label'].apply(clean_label)"
      ],
      "metadata": {
        "id": "AyNnjVdNedQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtering by location of abbreviation\n",
        "max_length = 200\n",
        "max_location = max_length - 3 # minus [CLS] and [SEP] tokens added and index offset\n",
        "\n",
        "def add_abbreviation_col(dataset):\n",
        "    \"\"\"Adds an abbreviation column to the dataset from the specified location in the text\"\"\"\n",
        "    dataset['abbreviation'] = dataset.apply(lambda row: row['text'].split()[row['location']], axis=1)\n",
        "    return dataset\n",
        "\n",
        "def clean_dataset(dataset):\n",
        "    dataset = dataset.loc[dataset['location'] <= max_location].copy()\n",
        "    add_abbreviation_col(dataset)\n",
        "    return dataset\n",
        "\n",
        "for dataset in [train, test, validation]:\n",
        "  clean_dataset(dataset)\n"
      ],
      "metadata": {
        "id": "OGNVUAD6YnHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting labels to integers\n",
        "def make_label_map(labels):\n",
        "  label_map = {}\n",
        "  for i in range(len(labels.unique())):\n",
        "    label_map[labels.unique()[i]] = i\n",
        "  return label_map\n",
        "\n",
        "label_map = make_label_map(train['label'])\n",
        "\n",
        "#making sure test and validation sets don't have any labels that don't appear in train set\n",
        "validation = validation[validation['label'].isin(valid_labels)]\n",
        "test = test[test['label'].isin(valid_labels)]\n",
        "\n",
        "#mapping labels to integers in datasets\n",
        "for dataset in [train, test, validation]:\n",
        "  dataset['label'] = dataset['label'].map(label_map)"
      ],
      "metadata": {
        "id": "8t60sM2_HVES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#masking abbreviations\n",
        "def mask_abbreviations(row):\n",
        "  \"\"\"Takes row as an input and transforms the text column to have [MASK] in place of abbreviations\"\"\"\n",
        "  text = row['text'].lower().split()\n",
        "  location = row['location']\n",
        "  mask = '[MASK]'\n",
        "  text[location] = mask\n",
        "  return ' '.join(text)\n",
        "\n",
        "#applying function to datasets\n",
        "train['text'] = train.apply(mask_abbreviations, axis=1)\n",
        "validation['text'] = validation.apply(mask_abbreviations, axis=1)\n",
        "test['text'] = test.apply(mask_abbreviations, axis=1)"
      ],
      "metadata": {
        "id": "HicZ3VRjHTkw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}